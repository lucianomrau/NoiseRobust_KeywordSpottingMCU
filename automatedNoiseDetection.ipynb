{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of different methods for detecting input noise data automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelsArchitecture import BinarizedInputNetwork, ConvNet , BinarizedWeightNetwork\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS =  list(set(['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go'] + ['unknown', 'silence']))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TESTSET_PATH = '/home/luciano/Downloads/speech_commands_test_set_v0.02/'\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "BATCH_SIZE = 16\n",
    "N_MELS = 64\n",
    "N_FFT = 512\n",
    "POWER = 2.0\n",
    "F_MIN = 50.0\n",
    "F_MAX = 7500.0\n",
    "HOP_LENGTH=round(SAMPLE_RATE*0.01)\n",
    "WIN_LENGTH=round(SAMPLE_RATE*0.025)\n",
    "DURATION_SEC = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133370/310594781.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  full_precision_model.load_state_dict(torch.load(\"full_precision.pth\"))\n",
      "/tmp/ipykernel_133370/310594781.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  BinaryWeights_model.load_state_dict(torch.load(\"BinaryWeights.pth\"))\n",
      "/tmp/ipykernel_133370/310594781.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  full_binary_model.load_state_dict(torch.load(\"full_binary_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load models\n",
    "input_shape = (1, 64, 101)  # Example input shape, adjust as needed\n",
    "num_classes = len(KEYWORDS)  # Example number of classes, adjust as needed\n",
    "\n",
    "full_precision_model = ConvNet().to(device)\n",
    "full_precision_model.load_state_dict(torch.load(\"full_precision.pth\"))\n",
    "\n",
    "BinaryWeights_model = BinarizedWeightNetwork(input_shape, num_classes).to(device)\n",
    "BinaryWeights_model.load_state_dict(torch.load(\"BinaryWeights.pth\"))\n",
    "\n",
    "full_binary_model = BinarizedInputNetwork(input_shape, num_classes).to(device)\n",
    "full_binary_model.load_state_dict(torch.load(\"full_binary_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from spectrogram import AudioDataset\n",
    "import scipy.signal as signal\n",
    "\n",
    "class AddNoiseOnTestset(AudioDataset):\n",
    "    \"\"\"\n",
    "    This class adds noise to the spectrogram audio data.\n",
    "    \"\"\"\n",
    "    def __init__(self, audio_path, \n",
    "                 n_mels, n_fft,hop_length,\n",
    "                 win_length,f_min,f_max,\n",
    "                 power,sample_rate,duration_seconds,\n",
    "                 keywords, device,noise_type=None,snr_db=3.0):\n",
    "        \n",
    "        TEST_LIST = \"testing_list.txt\"\n",
    "        with open(audio_path+TEST_LIST, 'r') as f:\n",
    "            audio_list = f.read().splitlines()\n",
    "\n",
    "        super().__init__(audio_path, audio_list,sample_rate,duration_seconds,keywords,device)\n",
    "        self.noise_type = noise_type\n",
    "        self.snr_db = snr_db\n",
    "        # white, pink, babble and classes from the UrbanSoundsDataset\n",
    "        self.noise_type_allowed = [None,'white',\n",
    "                                   'pink',\n",
    "                                   'babble',\n",
    "                                   'air_conditioner_background',\n",
    "                                   'car_horn_background',\n",
    "                                   'children_playing_background',\n",
    "                                   'dog_bark_background',\n",
    "                                    'drilling_background',\n",
    "                                    'engine_idling_background',\n",
    "                                    'gun_shot_background',\n",
    "                                    'jackhammer_background',\n",
    "                                    'siren_background',\n",
    "                                    'street_music_background',\n",
    "                                    'air_conditioner_foreground',\n",
    "                                   'car_horn_foreground',\n",
    "                                   'children_playing_foreground',\n",
    "                                   'dog_bark_foreground',\n",
    "                                    'drilling_foreground',\n",
    "                                    'engine_idling_foreground',\n",
    "                                    'gun_shot_foreground',\n",
    "                                    'jackhammer_foreground',\n",
    "                                    'siren_foreground',\n",
    "                                    'street_music_foreground']\n",
    "\n",
    "        assert self.noise_type in self.noise_type_allowed, \"Noise type not allowed\"  # TODO: implement more noise types\n",
    "        if self.noise_type != None:\n",
    "            self.noise_signal = self.__load_noise_signal()\n",
    "\n",
    "        transformation = torchaudio.transforms.MelSpectrogram(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            n_mels=n_mels,\n",
    "            win_length=win_length,\n",
    "            f_min=f_min,\n",
    "            f_max=f_max,\n",
    "            center=True,\n",
    "            power = power,\n",
    "            sample_rate=sample_rate,\n",
    "        )\n",
    "        self.mel_spectrogram = transformation.to(self._device)\n",
    "        \n",
    "\n",
    "    def __load_noise_signal(self):\n",
    "        if self.noise_type == 'white':\n",
    "            noise_signal = self.__white_noise()\n",
    "        elif self.noise_type == 'pink':\n",
    "            noise_signal = self.__pink_noise()\n",
    "        elif self.noise_type == 'babble':\n",
    "            noise_signal = self.__babble_noise()\n",
    "        else:\n",
    "            noise_signal = self.__urban_sounds_noise()\n",
    "        return noise_signal\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.noise_type != None:\n",
    "            signal, label = super().__getitem__(index)\n",
    "            # Add noise to the signal\n",
    "            signal_with_noise = torchaudio.functional.add_noise(waveform=torch.squeeze(signal),\n",
    "                                                                noise=torch.squeeze(self.noise_signal),\n",
    "                                                                snr=torch.tensor(self.snr_db),\n",
    "                                                                lengths=None)\n",
    "            signal_with_noise = torch.unsqueeze(signal_with_noise, 0)\n",
    "            signal_with_noise = signal_with_noise.to(self._device)\n",
    "            mel_spectro = self.mel_spectrogram(signal_with_noise)\n",
    "        \n",
    "        else:\n",
    "            signal, label = super().__getitem__(index)\n",
    "            mel_spectro = self.mel_spectrogram(signal)\n",
    "        # Convert to decibels\n",
    "        mel_spectro = torchaudio.transforms.AmplitudeToDB()(mel_spectro)\n",
    "        return mel_spectro, label\n",
    "\n",
    "        \n",
    "    def __white_noise(self):\n",
    "        noise = torch.randn(self._num_samples,device=self._device)\n",
    "        return noise\n",
    "    \n",
    "    def __pink_noise(self):\n",
    "        # Generate white noise\n",
    "        self._num_samples\n",
    "        white_noise = torch.randn(self._num_samples)\n",
    "\n",
    "        # Apply a filter to shape the white noise into pink noise\n",
    "        b, a = signal.butter(4, 0.05, 'highpass')  # High-pass filter to remove DC component\n",
    "        filtered_noise = signal.lfilter(b, a, white_noise)\n",
    "        \n",
    "        fft = torch.fft.rfft(torch.tensor(filtered_noise))\n",
    "        frequencies = torch.fft.rfftfreq(self._num_samples, d=1/self._sample_rate)\n",
    "        pink_filter = 1 / torch.sqrt(np.abs(frequencies + 1e-10))  # Avoid division by zero\n",
    "        pink_filter[0] = 0  # Remove DC component\n",
    "        # pink_filter = pink_filter.to(self._device)\n",
    "        pink_fft = fft * pink_filter\n",
    "\n",
    "        # Inverse FFT to get the time-domain signal\n",
    "        pink_noise = torch.fft.irfft(pink_fft)\n",
    "        pink_noise = pink_noise.to(torch.float32)\n",
    "\n",
    "        return pink_noise.to(self._device)\n",
    "    \n",
    "    def __babble_noise(self):\n",
    "        noise,sr = torchaudio.load(\"./noise/noisex-92/babble.wav\")\n",
    "        \n",
    "        noise = self._resample_if_necessary(noise, sr)\n",
    "        noise = noise.to(self._device)\n",
    "        noise = self._cut_if_necessary(noise)\n",
    "        noise = self._right_pad_if_necessary(noise)\n",
    "        return noise\n",
    "\n",
    "    def __urban_sounds_noise(self): #TODO: read the wav file name from the csv file\n",
    "        wav_dict = {\n",
    "                    'air_conditioner_background' : \"177621-0-0-0.wav\",\n",
    "                    'car_horn_background' : \"132073-1-0-0.wav\",\n",
    "                    'children_playing_background' : \"135776-2-0-32.wav\",\n",
    "                    'dog_bark_background' : \"102106-3-0-0.wav\",\n",
    "                    'drilling_background' : \"17913-4-1-0.wav\",\n",
    "                    'engine_idling_background' : \"46918-5-0-0.wav\",\n",
    "                    'gun_shot_background' : \"135527-6-0-0.wav\",\n",
    "                    'jackhammer_background' : \"180937-7-3-0.wav\",\n",
    "                    'siren_background' : \"106905-8-0-0.wav\",\n",
    "                    'street_music_background' : \"132016-9-0-0.wav\",\n",
    "                    'air_conditioner_foreground' : \"127873-0-0-0.wav\",\n",
    "                    'car_horn_foreground' : \"145577-1-0-0.wav\",\n",
    "                    'children_playing_foreground' : \"105415-2-0-1.wav\",\n",
    "                    'dog_bark_foreground' : \"101415-3-0-2.wav\",\n",
    "                    'drilling_foreground' : \"103199-4-0-0.wav\",\n",
    "                    'engine_idling_foreground' : \"103258-5-0-0.wav\",\n",
    "                    'gun_shot_foreground' : \"102305-6-0-0.wav\",\n",
    "                    'jackhammer_foreground' : \"103074-7-0-0.wav\",\n",
    "                    'siren_foreground' : \"157867-8-0-0.wav\",\n",
    "                    'street_music_foreground' : \"108041-9-0-11.wav\"\n",
    "                    }\n",
    "        \n",
    "        noise,sr = torchaudio.load(\"./noise/UrbanSound8K/\" + wav_dict[self.noise_type])\n",
    "        \n",
    "        noise = self._resample_if_necessary(noise, sr)\n",
    "        noise = noise.to(self._device)\n",
    "        noise = self._cut_if_necessary(noise)\n",
    "        noise = self._right_pad_if_necessary(noise)\n",
    "        noise = self._mix_down_if_necessary(noise)\n",
    "        return noise\n",
    "    \n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Confidence level of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole dataset in memory\n",
    "def load_in_memory(data_set):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for data, label in data_set:\n",
    "        all_data.append(data)\n",
    "        all_labels.append(label)\n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseless_testset = AddNoiseOnTestset(\n",
    "                audio_path=TESTSET_PATH,\n",
    "                n_mels=N_MELS,\n",
    "                n_fft=N_FFT, \n",
    "                hop_length=HOP_LENGTH,\n",
    "                win_length=WIN_LENGTH,\n",
    "                f_min=F_MIN,\n",
    "                f_max=F_MAX,\n",
    "                power=POWER,\n",
    "                sample_rate=SAMPLE_RATE,\n",
    "                duration_seconds=DURATION_SEC,\n",
    "                keywords=KEYWORDS,\n",
    "                device=device\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test_model_confidence(test_loader,model,device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_confidence = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "            probabilidades = F.softmax(outputs, dim=1)\n",
    "            confidence, _ = torch.max(probabilidades, dim=1)\n",
    "            all_confidence.extend(confidence)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy , (all_labels), all_preds, all_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compute the confidence for the noiseless testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the noisy test set into memory\n",
    "all_data, all_labels = load_in_memory(noiseless_testset)\n",
    "test_tensor = TensorDataset(torch.stack(all_data), torch.tensor(all_labels))\n",
    "test_loader = DataLoader(test_tensor, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Test the models with the current combination of SNR and noise type\n",
    "acc_full_precision, ground_truth_labels , predicted_labels, outputs_confidence = test_model_confidence(test_loader, full_precision_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean confidence for label 0 ('down'): 0.9747\n",
      "Mean confidence for label 1 ('go'): 0.9769\n",
      "Mean confidence for label 2 ('left'): 0.9900\n",
      "Mean confidence for label 3 ('no'): 0.9844\n",
      "Mean confidence for label 4 ('off'): 0.9687\n",
      "Mean confidence for label 5 ('on'): 0.9790\n",
      "Mean confidence for label 6 ('right'): 0.9871\n",
      "Mean confidence for label 7 ('silence'): 0.9660\n",
      "Mean confidence for label 8 ('stop'): 0.9944\n",
      "Mean confidence for label 9 ('unknown'): 0.9349\n",
      "Mean confidence for label 10 ('up'): 0.9826\n",
      "Mean confidence for label 11 ('yes'): 0.9923\n",
      "Mean confidence for all labels: 0.9776\n"
     ]
    }
   ],
   "source": [
    "def confidence_labels(ground_truth_labels, outputs_confidence):\n",
    "    # mean confidence values for each label\n",
    "    mean_confidence_per_label = {}\n",
    "\n",
    "    outputs_confidence = torch.stack(outputs_confidence)\n",
    "\n",
    "    for label in set(ground_truth_labels):\n",
    "        confidence_filtered = outputs_confidence[ground_truth_labels == label]\n",
    "        mean_confidence = torch.mean(confidence_filtered)\n",
    "        mean_confidence_per_label[label.item()] = mean_confidence.item()\n",
    "\n",
    "\n",
    "    for label, mean_confidence in mean_confidence_per_label.items():\n",
    "        print(f\"Mean confidence for label {label} ('{sorted(KEYWORDS)[label]}'): {mean_confidence:.4f}\")\n",
    "\n",
    "    return mean_confidence_per_label\n",
    "\n",
    "confidence_noiseless = confidence_labels(ground_truth_labels, outputs_confidence)\n",
    "\n",
    "mean_value = torch.mean(torch.stack(outputs_confidence))\n",
    "print(f\"Mean confidence for all labels: {mean_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I compare the confidence of the outputs when the test data have noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pink noise at 24 db\n",
    "noisy_testset = AddNoiseOnTestset(\n",
    "                audio_path=TESTSET_PATH,\n",
    "                n_mels=N_MELS,\n",
    "                n_fft=N_FFT, \n",
    "                hop_length=HOP_LENGTH,\n",
    "                win_length=WIN_LENGTH,\n",
    "                f_min=F_MIN,\n",
    "                f_max=F_MAX,\n",
    "                power=POWER,\n",
    "                sample_rate=SAMPLE_RATE,\n",
    "                duration_seconds=DURATION_SEC,\n",
    "                keywords=KEYWORDS,\n",
    "                device=device,\n",
    "                noise_type=\"pink\",\n",
    "                snr_db=24\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the noisy test set into memory\n",
    "all_data, all_labels = load_in_memory(noisy_testset)\n",
    "test_tensor = TensorDataset(torch.stack(all_data), torch.tensor(all_labels))\n",
    "test_loader = DataLoader(test_tensor, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Test the models with the current combination of SNR and noise type\n",
    "acc_full_precision, ground_truth_labels , predicted_labels, outputs_confidence = test_model_confidence(test_loader, full_precision_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean confidence for label 0 ('down'): 0.9560\n",
      "Mean confidence for label 1 ('go'): 0.9716\n",
      "Mean confidence for label 2 ('left'): 0.9817\n",
      "Mean confidence for label 3 ('no'): 0.9837\n",
      "Mean confidence for label 4 ('off'): 0.9468\n",
      "Mean confidence for label 5 ('on'): 0.9762\n",
      "Mean confidence for label 6 ('right'): 0.9798\n",
      "Mean confidence for label 7 ('silence'): 0.9677\n",
      "Mean confidence for label 8 ('stop'): 0.9800\n",
      "Mean confidence for label 9 ('unknown'): 0.9254\n",
      "Mean confidence for label 10 ('up'): 0.9760\n",
      "Mean confidence for label 11 ('yes'): 0.9892\n",
      "Mean confidence for all labels: 0.9696\n"
     ]
    }
   ],
   "source": [
    "def confidence_labels(ground_truth_labels, outputs_confidence):\n",
    "    # mean confidence values for each label\n",
    "    mean_confidence_per_label = {}\n",
    "\n",
    "    outputs_confidence = torch.stack(outputs_confidence)\n",
    "\n",
    "    for label in set(ground_truth_labels):\n",
    "        confidence_filtered = outputs_confidence[ground_truth_labels == label]\n",
    "        mean_confidence = torch.mean(confidence_filtered)\n",
    "        mean_confidence_per_label[label.item()] = mean_confidence.item()\n",
    "\n",
    "\n",
    "    for label, mean_confidence in mean_confidence_per_label.items():\n",
    "        print(f\"Mean confidence for label {label} ('{sorted(KEYWORDS)[label]}'): {mean_confidence:.4f}\")\n",
    "\n",
    "    return mean_confidence_per_label\n",
    "\n",
    "confidence_pink_3db = confidence_labels(ground_truth_labels, outputs_confidence)\n",
    "\n",
    "mean_value = torch.mean(torch.stack(outputs_confidence))\n",
    "print(f\"Mean confidence for all labels: {mean_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "difference in the ouput confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9747442603111267,\n",
       " 1: 0.9768653512001038,\n",
       " 2: 0.9899606704711914,\n",
       " 3: 0.9843631982803345,\n",
       " 4: 0.9686923027038574,\n",
       " 5: 0.979042112827301,\n",
       " 6: 0.987056314945221,\n",
       " 7: 0.9659756422042847,\n",
       " 8: 0.9943723678588867,\n",
       " 9: 0.9349432587623596,\n",
       " 10: 0.9825799465179443,\n",
       " 11: 0.9923374056816101}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_noiseless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence diffence for label 0 ('down'): 0.0187\n",
      "Confidence diffence for label 1 ('go'): 0.0052\n",
      "Confidence diffence for label 2 ('left'): 0.0083\n",
      "Confidence diffence for label 3 ('no'): 0.0006\n",
      "Confidence diffence for label 4 ('off'): 0.0218\n",
      "Confidence diffence for label 5 ('on'): 0.0029\n",
      "Confidence diffence for label 6 ('right'): 0.0072\n",
      "Confidence diffence for label 7 ('silence'): -0.0018\n",
      "Confidence diffence for label 8 ('stop'): 0.0144\n",
      "Confidence diffence for label 9 ('unknown'): 0.0096\n",
      "Confidence diffence for label 10 ('up'): 0.0066\n",
      "Confidence diffence for label 11 ('yes'): 0.0031\n"
     ]
    }
   ],
   "source": [
    "for label in set(ground_truth_labels):\n",
    "    print(f\"Confidence diffence for label {label} ('{sorted(KEYWORDS)[label]}'): {confidence_noiseless[label]-confidence_pink_3db[label]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
